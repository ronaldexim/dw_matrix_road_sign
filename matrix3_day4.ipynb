{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matrix3_day4.ipynb",
      "provenance": [],
      "mount_file_id": "14WCdVzqmArZAsONaf7V-9yQS7eZDnxn9",
      "authorship_tag": "ABX9TyNHYjWiqype43pb/PcNMS3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaldexim/dw_matrix_road_sign/blob/master/matrix3_day4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcBQkNaxMXNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os, datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import color, exposure\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTMfXAliM1kd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e37872c9-defd-47b3-9318-f4978ed79fd9"
      },
      "source": [
        "cd '/content/drive/My Drive/Colab Notebooks/dw_matrix/matrix_three/dw_matrix_road_sign/data'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/dw_matrix/matrix_three/dw_matrix_road_sign/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRJvX83VPdOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = pd.read_csv('signnames.csv')\n",
        "labels_dict = names.to_dict()['b']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5FH0H7AM-tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_pickle('train.p')\n",
        "test = pd.read_pickle('test.p')\n",
        "X_train, y_train = train['features'], train['labels']\n",
        "X_test, y_test = test['features'], test['labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-UQD0UlNP0B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8746c07b-6205-4a52-8fe4-384c272c3892"
      },
      "source": [
        "if y_train.ndim == 1: y_train = to_categorical(y_train)\n",
        "if y_test.ndim == 1: y_test = to_categorical(y_test)\n",
        "y_train.shape, y_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((34799, 43), (4410, 43))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5GF2X3pNUXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "num_classes = y_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28tp0M-_NXkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cnn_v1(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
        "        Flatten(),\n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def get_cnn_v2(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.5),   \n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, params_fit={}):\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics='accuracy')\n",
        "\n",
        "        logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "        model.fit(\n",
        "            X_train, \n",
        "            y_train,\n",
        "            batch_size = params_fit.get('batch_size', 128),\n",
        "            epochs = params_fit.get('epochs', 5),\n",
        "            verbose = params_fit.get('verbose', 1),\n",
        "            validation_data = params_fit.get('validation_data', (X_train, y_train)),\n",
        "            callbacks = [tensorboard_callback]\n",
        "            )\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iisiGGx1Nck8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "db96b996-cddf-411f-ee5e-90dd5df6303c"
      },
      "source": [
        "params_fit ={\n",
        "    'epochs': 25\n",
        "}\n",
        "\n",
        "model_trained = train_model(get_cnn_v1(input_shape, num_classes), X_train, y_train, params_fit)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "272/272 [==============================] - 3s 9ms/step - loss: 37.0506 - accuracy: 0.7372 - val_loss: 0.2123 - val_accuracy: 0.9496\n",
            "Epoch 2/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1971 - accuracy: 0.9547 - val_loss: 0.0993 - val_accuracy: 0.9772\n",
            "Epoch 3/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1285 - accuracy: 0.9705 - val_loss: 0.0700 - val_accuracy: 0.9828\n",
            "Epoch 4/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1132 - accuracy: 0.9745 - val_loss: 0.0703 - val_accuracy: 0.9838\n",
            "Epoch 5/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0899 - accuracy: 0.9798 - val_loss: 0.0396 - val_accuracy: 0.9909\n",
            "Epoch 6/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0888 - accuracy: 0.9811 - val_loss: 0.0983 - val_accuracy: 0.9777\n",
            "Epoch 7/25\n",
            "272/272 [==============================] - 2s 8ms/step - loss: 0.0833 - accuracy: 0.9808 - val_loss: 0.0573 - val_accuracy: 0.9864\n",
            "Epoch 8/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0726 - accuracy: 0.9847 - val_loss: 0.0671 - val_accuracy: 0.9860\n",
            "Epoch 9/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0806 - accuracy: 0.9837 - val_loss: 0.1273 - val_accuracy: 0.9732\n",
            "Epoch 10/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0735 - accuracy: 0.9847 - val_loss: 0.0530 - val_accuracy: 0.9883\n",
            "Epoch 11/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0718 - accuracy: 0.9860 - val_loss: 0.0530 - val_accuracy: 0.9888\n",
            "Epoch 12/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0653 - accuracy: 0.9869 - val_loss: 0.0329 - val_accuracy: 0.9931\n",
            "Epoch 13/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0725 - accuracy: 0.9870 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
            "Epoch 14/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0948 - accuracy: 0.9823 - val_loss: 0.0735 - val_accuracy: 0.9878\n",
            "Epoch 15/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0576 - accuracy: 0.9887 - val_loss: 0.0387 - val_accuracy: 0.9912\n",
            "Epoch 16/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0569 - accuracy: 0.9893 - val_loss: 0.0406 - val_accuracy: 0.9917\n",
            "Epoch 17/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0379 - accuracy: 0.9924 - val_loss: 0.0801 - val_accuracy: 0.9897\n",
            "Epoch 18/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0770 - accuracy: 0.9880 - val_loss: 0.0535 - val_accuracy: 0.9890\n",
            "Epoch 19/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0684 - accuracy: 0.9876 - val_loss: 0.0316 - val_accuracy: 0.9951\n",
            "Epoch 20/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0466 - accuracy: 0.9913 - val_loss: 0.0498 - val_accuracy: 0.9922\n",
            "Epoch 21/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0616 - accuracy: 0.9893 - val_loss: 0.0261 - val_accuracy: 0.9956\n",
            "Epoch 22/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0594 - accuracy: 0.9907 - val_loss: 0.0395 - val_accuracy: 0.9938\n",
            "Epoch 23/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1080 - accuracy: 0.9841 - val_loss: 0.0640 - val_accuracy: 0.9889\n",
            "Epoch 24/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0888 - accuracy: 0.9863 - val_loss: 0.0715 - val_accuracy: 0.9903\n",
            "Epoch 25/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.0416 - accuracy: 0.9939 - val_loss: 0.0196 - val_accuracy: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dthWYZONNnUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "515b1ce4-5823-4d60-e809-f7379bb3b302"
      },
      "source": [
        "y_pred_prob = model_trained.predict(X_test)\n",
        "y_pred_prob[400]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.5061661e-18, 9.9998879e-01, 7.3409547e-31, 0.0000000e+00,\n",
              "       1.1175117e-05, 9.1999237e-25, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 2.5063966e-38, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FblbFrmLOZlQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "691b172f-4613-48fc-d167-9096fe82d081"
      },
      "source": [
        "plt.imshow(X_test[400]);"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcSElEQVR4nO2de4ykZ3Xmn1O3vl/c0z33Gfd4fMvY\nGNu0HIOJY8hCDHFiSFYI/kD+AzHRKkiLlP3DItHilSItrAIIaVeshsWKE7FcEiBYEQk4huAYwuC2\nsceDbWbG4/F0z0z39PT9WteTP6pGO/a+z9ft7q6qxu/zk0ZT/Z5663vr63rqq36fOueYu0MI8eYn\n1ewFCCEag8QuRCRI7EJEgsQuRCRI7EJEgsQuRCRkNjLZzO4F8EUAaQD/x90/k3T//v5+Hxwc3Mgh\nBQAUizR0cXwsOD63tETnVBLsV4PxdSTZtiRkqTSdsmvPbhrr6Ozgx3qT4l7hsXIpOH52ZBSXJqeC\nv7R1i93M0gD+F4D3ABgF8JSZPeruL7A5g4ODGB4eXu8hRY3y2AUa+59/+dng+A9/8Syds1QIv3AA\nIJVK+PBX5PNQDr9Qsy19dMqf//eHaOzOu+7gx/o1p1IJn6tyib9Bl2amguN3vfc+OmcjH+PvAHDK\n3U+7ewHA1wHcv4HHE0LUkY2IfQ+AkSt+Hq2NCSG2IHXfoDOzw2Y2bGbDExMT9T6cEIKwEbGfA7Dv\nip/31sZeg7sfcfchdx8aGBjYwOGEEBthI2J/CsB1ZnbAzHIAPgzg0c1ZlhBis1n3bry7l8zsEwC+\nj6r19rC7/3LTVhY9BRpZnDpPY740Hw5Ygr2WEEuy15IyJpmdl/WEHfxCOWEdPJT03ABmX3FbK/ka\nyK3DJLzMn9v84kJwfHLsFTpn+dLF4Hh+ZYXO2ZDP7u7fA/C9jTyGEKIx6Bt0QkSCxC5EJEjsQkSC\nxC5EJEjsQkTChnbjxUZJsn/CiQ4AsLB8lsaWi2EbJ2Xc+mlNeBVYhWe9VVI8ViLJHahwa2h5Nrx2\nAJid4pl+ZZ+hsUppOjieydIp6OnbS2Nm7XxiAsUyT2qZGDsVHJ8a5984TRfDv88kO1RXdiEiQWIX\nIhIkdiEiQWIXIhIkdiEiQbvxWxSv8PfhOec76wvZ8C5+LscTa3LoobG2bCuNWZnv/K6shBNylkuz\ndM7R4cdprKNvH421d+RprJy/FBxP5biT0NlzNY2livw8zsyHjwUAF2b5zvrMyGhwvMX5GlPpNy5d\nXdmFiASJXYhIkNiFiASJXYhIkNiFiASJXYhIaIL1llQv7I3OSWhNlBjbbJISWpLgayRlyQAAF6cX\naew333VTcPwgd4XQ03UDjXW3cVsuw5JdAEyOnQ6OF/Ov0jldXW00VpgK11wDgHSZv4zz+bAtd/WB\nQX6sWV4nb/xcOLEGAKbnf0VjM3M8WSdNnNRUlr8+0q0t4YAl2HU0IoR4UyGxCxEJErsQkSCxCxEJ\nErsQkSCxCxEJG7LezOwMgHkAZQAldx9KnlEBwGqQJRQFA7OacglzuI2zfsJWk3uCT5Zgr5l10lhn\ndz+N3f0fPkBjlbkbg+PluQt0TrnMrablBX49SJV5tlnnoWvIwcg4gFTnQRrLZ6+nsfkVbstNTYRf\nO70JNt/0y7yL2dj0HI2tFEjrLQCZSoLlnAnLsJx0Kc50hMeNT9oMn/1d7p7g4gohtgL6GC9EJGxU\n7A7gB2b2tJkd3owFCSHqw0Y/xr/T3c+Z2XYAj5nZS+7+xJV3qL0JHAaA/ft5tREhRH3Z0JXd3c/V\n/r8I4DsA7gjc54i7D7n70MAA33QSQtSXdYvdzDrMrOvybQDvBXB8sxYmhNhcNvIxfgeA71g1yyYD\n4P+6+z8lT6kAZWJTpbkNtf6ssk2GuCeVIreuktaeTnM7xs+P8Ngct5ryI+H3W5s4QecU8wntk/Lc\nErU0txXLrenw4+WuonMyu/n5SA+EHw8Atu3gj9nRtjs4vjLFbbLpGW4uFfK8jZMZl1NC7UgUiIO8\nex8vfLmnd1dwvCVHsuGwAbG7+2kAb13vfCFEY5H1JkQkSOxCRILELkQkSOxCRILELkQkNLbgpJeB\nCrF50txagbeHh50vPyH5Z/2QYn6pTBefU+bFIcsnjtLY/DM/5LFJnsGWXw5nFWazPEMw3cHXn2rj\n2WGWkNG3sLwcHC/PhnvRAUBq6kka88zPaaxr77U01nvbe4Ljmd79dE73Iu/ntlgK92UDgLzz17C1\ncHv2mmt3Bsd37OTPqz0T1kQ6w61SXdmFiASJXYhIkNiFiASJXYhIkNiFiISG78Z7PlzDy/OkBw6A\nSjm8yzk7xZNM+vbzlkaWsPGfTPh4VpqkM0ov8V3kmZ8+RmPZ2bM01rt7L43hhncGh1v38Rpuqd17\n+OMlXQ9KRR4jzkVlhD8vmx+nsYWXfsaPdfI5GppdDCe8dL/jfXTO9r3baaxQ5q+56fwEjfUfuI7G\n9u8/EBxPp8I77rVoeDgh4UZXdiEiQWIXIhIkdiEiQWIXIhIkdiEiQWIXIhIaar15qYQyqe+1ssBt\ni4XFcHLHxCy3Jlp7eJuhjr6kVlMJFMPtjoq//Amdsvxv3+exaZ4UkrmBW2Vd7/p9GsO2/6/Ab41W\nPqeBpLdxCwrO68J1DfTR2MzP/oXGKudOBscXfjrLj/VbH6ex7Qd4ckqX99BY/w5ub6ZSSfUXNw9d\n2YWIBIldiEiQ2IWIBIldiEiQ2IWIBIldiEhY1Xozs4cB3AfgorvfXBvrA/ANAIMAzgD4kLtPr/pY\ncKRJ1lCuzN938vPhDJ+lFT6nVOJZdIUCt97SxlsQYTRc+2326af4sSa5pdhz8GYa6/7tD/F1bOO2\nIsBrzW15jFup6WvvorHeMm//tPzzfw6OT4/8ii/jGZ6p2H33B3ism9tyW4G1XNn/CsC9rxt7EMDj\n7n4dgMdrPwshtjCrir3Wb/313/64H8AjtduPAOBvd0KILcF6/2bf4e6XP9OOodrRVQixhdnwBp27\nO2gzY8DMDpvZsJkNT0yFq9QIIerPesU+bma7AKD2P20Y7u5H3H3I3YcG+rrXeTghxEZZr9gfBfBA\n7fYDAL67OcsRQtSLtVhvXwNwD4B+MxsF8GkAnwHwTTP7GIBXAST4RP8PL5dQmgsXFSwu8KUUlsNW\nWTFh+flSOEMNAObHeEumbd38/a9ykhQ9nDpP5+T2cZus891/RGO+jds4pYlwFiAA+EL4eVuatzTK\n7NlGY5ZeX4Yg+7uuUuEFG32e26WpNp4Zlr7+NhprQ/hcLf7ry3QORn5BQ0snefZa+1vu5I+Z4220\nGsWqYnf3j5DQ72zyWoQQdUTfoBMiEiR2ISJBYhciEiR2ISJBYhciEhpacLLiZSzkw4X+8is82yyX\n6gqO9xlf/qXTx2isb+c+GssWuGU38cqT4TllboW1vvXtNJYauJHGFi7yJMKXn3iaxlaWwlZZpsyL\nOe6+/SCN7biZZ+ZZljfNm6iEbbSJ87wvXuoU/4ZlJsX7rw2+rYPGsjfeFBzvnX8LnTOfkMVoS+EC\nlgDQbm+jMaD51puu7EJEgsQuRCRI7EJEgsQuRCRI7EJEgsQuRCQ01HpLZdvQtTds5aTPn6LzejPh\nIorW1kvnXJrlGVQt7QmZbaMjNJa/FLaGuvt+g87JdSQUIXS+jnRC3cvBm3m/tJ6r9wfHZ371Kp3z\nzFPP0Vi2j1tePXt5JtqrZ8MW1fQ4t8luTbBEzw3TkgkYWQr3DwSAA/eEsw5zB/6Azkmf5Lbn4gh/\nfZRv4L370tubX8tBV3YhIkFiFyISJHYhIkFiFyISJHYhIqGhu/GWTiHVFU5qyfXwtkWVcik4nu7l\nc/LzPKGlM5Ow1T0xRkPpSvi9MXuAJ4tk9/NkFxCXAQDadu1aVwwefm7W3kKnrCTElniVcLQtLdPY\n9JM/CY6/9bb76Jy+a/jufrZQ5McafpHGUCJuSAc/h9beT2OpBf76QDH8Ot0q6MouRCRI7EJEgsQu\nRCRI7EJEgsQuRCRI7EJEwlraPz0M4D4AF9395trYQwA+DmCidrdPufv3Vj2aF4HyhWCo4gsJawgv\n04wnu7TleH209lajMSzyZIaUh1sXldvb+eO1tvJYHZgYD9s/J8+cpnN6B7kFuHM3bw1VmONttFIr\nYTtv+4GddI4ldJpKcAdBDlV9TBbI8etcppPXi/NJ3kYLK9yKZJYoAMASXo+byFqu7H8F4N7A+Bfc\n/dbav9WFLoRoKquK3d2fAMAvd0KIXws28jf7J8zsmJk9bGZXbdqKhBB1Yb1i/xKAgwBuBXABwOfY\nHc3ssJkNm9nwxCSvCy6EqC/rEru7j7t72d0rAL4M4I6E+x5x9yF3HxrY1vxqHULEyrrEbmZXZhF8\nEMDxzVmOEKJerMV6+xqAewD0m9kogE8DuMfMbgXgAM4A+OM1Hc0LQH40GMq18IyhVKUnOF5MaJHU\nSuYAQCbhLa5S5nZeNhM+XdmWBO+nwZyfDLd5mmnjtd+60/w557LclivOjNNYZj78+7TZcPsvAEAH\nX2MhF7Y9AWA2xTPidrFfTYIThjS3bb3EW32hkPDcygm2XCbBut1EVhW7u38kMPyVOqxFCFFH9A06\nISJBYhciEiR2ISJBYhciEiR2ISKhoQUnAYelwxZEpp1nGi1NhbOCLs3zrCtPsIw6nGcZpVM89apc\nDvs1lRK3hRrNdXvC31zevcztnROjZ2isklDosdLXR2OLvSS7rW+Azkmyw4oJztXcMp/oxNEliZQ1\n+O+zVOTWWykhCzOdbv51tfkrEEI0BIldiEiQ2IWIBIldiEiQ2IWIBIldiEhosPUGVMrhQ05Pc29l\nbiY8Z2qGz8m28V5vvSu/QWO5DM+8KpbDll0lqSYHXwbKCRZPcYlPbE0oiNhOkv0WM/xY5Ty3jBJK\nNgLOrxUOvkY+hzMyy4817twuZeUhcwnZjYVZXoXNSOYjAFiul8Zg3ApuFLqyCxEJErsQkSCxCxEJ\nErsQkSCxCxEJDd2NLxcd8xfCO+gvjMzQeSWEsxlaKnyHuVDgu9n5Rb6L37ZzF42VyNZ6euIFOsdn\nD9GY9e6gsaWzL9PY3MVwCy0A6L7ppuD4+Dw/V5WuvTSWyvH6ejb1Ko11LJwJjpcv8d+z7eStplI9\n/Dl3XM93ulNZsuueT6ifV+atyHLdvLZhurWTxrbCdbX5KxBCNASJXYhIkNiFiASJXYhIkNiFiASJ\nXYhIWEv7p30A/hrADlRzFY64+xfNrA/ANwAMotoC6kPuzvsxASgUHaNj4Zpm01MJaRAWtmvaerjV\nkSJJKwCQn5jg83ZyOyzdHbahls49See0nOe2Vuu2+3hsbxeNnT71FI299MOwReV9PPnnhlveQWNJ\ntO7mde2uuTlsUb3y7Hk656pbuF26Z8ezNLZ/7+00lq1MBseLx/+JzilPnaWx3J6wtQkA6c4k6635\nrOXKXgLwp+5+CMCdAP7EzA4BeBDA4+5+HYDHaz8LIbYoq4rd3S+4+zO12/MAXgSwB8D9AB6p3e0R\nAB+o1yKFEBvnDf3NbmaDAG4DcBTADne//JlxDNWP+UKILcqaxW5mnQC+BeCT7v6acg3u7iC1B8zs\nsJkNm9nw9Cyv8y6EqC9rEruZZVEV+lfd/du14XEz21WL7wJwMTTX3Y+4+5C7D13Vw6vACCHqy6pi\nNzNDtR/7i+7++StCjwJ4oHb7AQDf3fzlCSE2i7Vkvd0F4KMAnjezy/7HpwB8BsA3zexjAF4F8KHV\nHqhUBi7OkDpuBf6+k2WrLPM5LVmerVUuj/FYO7e8uveE7avl40fpnMLPnqexXO9v01j71fto7Ob3\n/SGNIdNKDsbPx3rJtG+nsavf8XvB8bPP8ay3hSVeF25H3x001preTWN+Kpw9OHXsOJ2TLfL6eW3b\nb6Ax5Lb2J9dVxe7uT4JXHfydzV2OEKJe6Bt0QkSCxC5EJEjsQkSCxC5EJEjsQkRCw9s/sW39XEJb\nnVw2PCuV4oUGFxOempWWaKx3hWdedd32W8Hx/NhJOgcXz9DQylP/RmNtbXfRmO3ghRkbS0JLo9Zw\nbM9tV9EplnDpSZGiowCAMyM8diKcLbcywzMf2w/dzWM3/SY/VivPAtwK6MouRCRI7EJEgsQuRCRI\n7EJEgsQuRCRI7EJEQkOtN/MSWirhmpSZFp6Vlc2Gs5C6WnmWUSrHi/95ifc9mzx7icY69lwbHO9/\nN7fJ5n/8jzx2hmcFe5r/atrfzrPlbCfJeqOmJ5I9r3BNktUfk8xLZxMer8yz3vw0r2VaOPb3NDb5\nyo+D4627uH3Z+fawxVoNDvBYI6+dlaTfSxhd2YWIBIldiEiQ2IWIBIldiEiQ2IWIhIbuxqcMaE2F\nd8IL5XBbKADIeHiH2Uo8aaU9xd/HKmW+kzk1yXd9RxfD9dN27+N1yXru5Ikfkz/9No2VTn6fxmaW\nX6Wx9qHrg+OZtj10Trp/kMaQ4zvkSbkpvhAuG15e4kkrxbNnaGzp2Zf4weZ4a6j2feHn3X0H72li\nHfv5sRp5feSSQOlCuI6iF/gkXdmFiASJXYhIkNiFiASJXYhIkNiFiASJXYhIWNV6M7N9AP4a1ZbM\nDuCIu3/RzB4C8HEAl4t5fcrdv5f0WGUAcySWlFJRJHZCsTRL50w5jxUSLKPFwjKNLaAQHF8eP0Dn\nDF47RGM99/BjXfpXXp+uNMLbTRXH/iU43nHVLXRObvfbaAy93KZMhU8HAKDwSthiK00/R+csTAV7\ngwIA5oo8UarvlrDdCAC99/xucDw1kFBLLrP5rbISfbSl+eBw/gRvlXXpVNiKLC3y+opr8dlLAP7U\n3Z8xsy4AT5vZY7XYF9z9L9fwGEKIJrOWXm8XAFyo3Z43sxcB8G9oCCG2JG/ob3YzGwRwG4DLnyM/\nYWbHzOxhM+NfFRNCNJ01i93MOgF8C8An3X0OwJcAHARwK6pX/s+ReYfNbNjMhmfn+N+oQoj6siax\nm1kWVaF/1d2/DQDuPu7uZXevAPgygGADbXc/4u5D7j7U0837Xgsh6suqYjczA/AVAC+6++evGN91\nxd0+CIB3txdCNJ217MbfBeCjAJ43s8vpRZ8C8BEzuxVVO+4MgD9e7YGKpRIuXJoKxrpaeuk88/B7\nUrHAvR9LZWmskk6IZfinj2ni2Xl+lM7Zmd1FY32H3kdj21veQmOlU9y+8qmfBMcvjT7PH2/0DI2h\nzDML084N08JyeF62hWfR9fbfSGNdB99LY513cesTV/WFx42/BupBpcBtxemj4QzHc0+fpXMm58IW\n28py2MYD1rYb/yTCNniipy6E2FroG3RCRILELkQkSOxCRILELkQkSOxCREKD2z8BadJ5qVTiqWjF\ncnjS/DJv49TbyS20YkL7p2KC9dadC9uDfQPE3gGQyiac4kwPD13LrUgMJHwzeY6s8QIvpIkJfu6X\nxsJWKQBkjWfEVfq6g+Mt11xD5+S69vJj7TxIY+hsrI1GSShkWjhxjsYWXz5DHo9/43TJwll0lYR2\nXbqyCxEJErsQkSCxCxEJErsQkSCxCxEJErsQkdDYXm+pFDpa2oMxT8hCWi6Gs6sKxJIDgHyJZ1el\njGdrtaTCfeUA4IZD4SKFVx8cpHOyCRl2iWU20zx2booXIrSlXHC8v59n0WV7umhsom2SxnJ9fF53\nb9jCbNs2QOekEuxSZLbIdWmFZ1rOn+AZZyeHeX+++Znw7zrT0knndObCr/1UOk3nbJEzKISoNxK7\nEJEgsQsRCRK7EJEgsQsRCRK7EJHQUOutUgFW8uEMq7llnnk1vxIuXphp4T25lla4DZJL86fd08kz\n0Xq6w7ZhEdwysjK3QpLsNW4cAn07eHZYYS68Fs+G1w4ARYTtOgDwHLcOF3rDmW0AYOQZtLbzY6W2\nir2W0JZt9tkzNPbCj39AY6NT3HqbLYY7IGYy/Nx3EYutlGQ504gQ4k2FxC5EJEjsQkSCxC5EJEjs\nQkTCqrvxZtYK4AkALbX7/527f9rMDgD4OoBtAJ4G8FF351kCAEqVCiaWwneZCnezAQCkM+Ed3Hbn\nO4/lhPexrj7eXr7rqh18IaTdUXuGJ89YQrLLQoUn8ozN82SXTIU7Fzt37guOtyWcD0twJ/Zt30Zj\nI5Pc8ejqCLsamUxC8k8jqfBabcWzvF7f+KlTNLa4dIHGMpUFGtvZFnZQ0gm/lwxJ5konJHmt5cqe\nB/Bud38rqu2Z7zWzOwF8FsAX3P1aANMAPraGxxJCNIlVxe5VLr8tZWv/HMC7AfxdbfwRAB+oywqF\nEJvCWvuzp2sdXC8CeAzAywBm3P3y58lRAPyzsRCi6axJ7O5edvdbAewFcAcA3lv3dZjZYTMbNrPh\nhUXe/lcIUV/e0G68u88A+BGAtwPoNbPLOwh7AQSr4Lv7EXcfcvehzg7+9VYhRH1ZVexmNmBmvbXb\nbQDeA+BFVEX/H2t3ewDAd+u1SCHExllLIswuAI+YWRrVN4dvuvs/mNkLAL5uZn8B4BcAvrLaA5Ud\nmF8J22ULeZ4w0t8ajt1y4Go6p2Pbdhpr7bmZxpISRjKt4bZL6dQ67aQl3t7n+E9+RGM7d/TTWP+N\n4edWSPEElJY2XktuKcESPfHCeRprv/7a8HhfQo20pNOYEEtwYFEifzmOn+bZLqO/OEpjy1Mv0Fiq\nkz+3nk5eey+bDv9uPCEjp1AgsYSTuKrY3f0YgNsC46dR/ftdCPFrgL5BJ0QkSOxCRILELkQkSOxC\nRILELkQkmDvP/tn0g5lNALhcjKsfwKWGHZyjdbwWreO1/Lqt42p3D/p8DRX7aw5sNuzuQ005uNah\ndUS4Dn2MFyISJHYhIqGZYj/SxGNfidbxWrSO1/KmWUfT/mYXQjQWfYwXIhKaInYzu9fMfmVmp8zs\nwWasobaOM2b2vJk9a2bDDTzuw2Z20cyOXzHWZ2aPmdnJ2v/hFLv6r+MhMztXOyfPmtn7G7COfWb2\nIzN7wcx+aWb/uTbe0HOSsI6GnhMzazWzn5vZc7V1/Lfa+AEzO1rTzTfMjKcyhnD3hv4DkEa1rNU1\nAHIAngNwqNHrqK3lDID+Jhz3bgC3Azh+xdj/APBg7faDAD7bpHU8BOC/NPh87AJwe+12F4ATAA41\n+pwkrKOh5wTVhN7O2u0sgKMA7gTwTQAfro3/bwD/6Y08bjOu7HcAOOXup71aevrrAO5vwjqahrs/\nAWDqdcP3o1q4E2hQAU+yjobj7hfc/Zna7XlUi6PsQYPPScI6GopX2fQir80Q+x4AI1f83MxilQ7g\nB2b2tJkdbtIaLrPD3S8XHh8DkFDAvu58wsyO1T7m1/3PiSsxs0FU6yccRRPPyevWATT4nNSjyGvs\nG3TvdPfbAbwPwJ+Y2d3NXhBQfWdH9Y2oGXwJwEFUewRcAPC5Rh3YzDoBfAvAJ939NX2MG3lOAuto\n+DnxDRR5ZTRD7OcAXNm2hBarrDfufq72/0UA30FzK++Mm9kuAKj9f7EZi3D38doLrQLgy2jQOTGz\nLKoC+6q7f7s23PBzElpHs85J7dhvuMgroxlifwrAdbWdxRyADwN4tNGLMLMOM+u6fBvAewEcT55V\nVx5FtXAn0MQCnpfFVeODaMA5MTNDtYbhi+7++StCDT0nbB2NPid1K/LaqB3G1+02vh/Vnc6XAfxZ\nk9ZwDapOwHMAftnIdQD4GqofB4uo/u31MVR75j0O4CSAfwbQ16R1/A2A5wEcQ1Vsuxqwjnei+hH9\nGIBna//e3+hzkrCOhp4TALegWsT1GKpvLP/1itfszwGcAvC3AFreyOPqG3RCRELsG3RCRIPELkQk\nSOxCRILELkQkSOxCRILELkQkSOxCRILELkQk/DtR6ecMpL89dAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YkX9xb8O7N6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2871a20-97ad-4719-ec8d-ca8de5bf141a"
      },
      "source": [
        "labels_dict[np.argmax(y_pred_prob[400])]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Speed limit (30km/h)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCwbFTX3QLNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7fd08467-8a10-4894-b257-776ef7f122f3"
      },
      "source": [
        "plt.bar(range(43), y_pred_prob[400])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 43 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Sq8Bt-Q_-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model_trained, X_test, y_test, scoring=accuracy_score):\n",
        "\n",
        "    y_test_norm = np.argmax(y_test, axis=1)\n",
        "\n",
        "    y_pred_prob = model_trained.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "    return scoring(y_test_norm, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JANj9BVRT18g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a88dff61-1677-46e6-e8e9-5cc620d24a59"
      },
      "source": [
        "predict(model_trained, X_test, y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8793650793650793"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h71tk-tuUZae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_predict(model):\n",
        "    model_trained = train_model(model, X_train, y_train, params_fit)\n",
        "    return predict(model_trained, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQx1XwzWVjCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2118e81b-9fc7-4d79-ef60-d48316ed61e2"
      },
      "source": [
        "def get_cnn_v3(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.3),   \n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    model.summary()\n",
        "    return model\n",
        "train_predict(get_cnn_v3(input_shape, num_classes))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 2,423,787\n",
            "Trainable params: 2,423,787\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "272/272 [==============================] - 3s 10ms/step - loss: 5.7087 - accuracy: 0.2361 - val_loss: 1.4488 - val_accuracy: 0.6134\n",
            "Epoch 2/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 1.3920 - accuracy: 0.5893 - val_loss: 0.5173 - val_accuracy: 0.8651\n",
            "Epoch 3/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.7579 - accuracy: 0.7684 - val_loss: 0.2934 - val_accuracy: 0.9371\n",
            "Epoch 4/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.5113 - accuracy: 0.8437 - val_loss: 0.1451 - val_accuracy: 0.9702\n",
            "Epoch 5/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.3823 - accuracy: 0.8833 - val_loss: 0.1160 - val_accuracy: 0.9759\n",
            "Epoch 6/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.3071 - accuracy: 0.9081 - val_loss: 0.0941 - val_accuracy: 0.9796\n",
            "Epoch 7/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.2491 - accuracy: 0.9257 - val_loss: 0.0459 - val_accuracy: 0.9913\n",
            "Epoch 8/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.2070 - accuracy: 0.9391 - val_loss: 0.0427 - val_accuracy: 0.9929\n",
            "Epoch 9/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1907 - accuracy: 0.9424 - val_loss: 0.0323 - val_accuracy: 0.9941\n",
            "Epoch 10/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1715 - accuracy: 0.9504 - val_loss: 0.0219 - val_accuracy: 0.9957\n",
            "Epoch 11/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1482 - accuracy: 0.9560 - val_loss: 0.0218 - val_accuracy: 0.9951\n",
            "Epoch 12/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1552 - accuracy: 0.9553 - val_loss: 0.0160 - val_accuracy: 0.9977\n",
            "Epoch 13/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1458 - accuracy: 0.9579 - val_loss: 0.0136 - val_accuracy: 0.9969\n",
            "Epoch 14/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1356 - accuracy: 0.9606 - val_loss: 0.0144 - val_accuracy: 0.9973\n",
            "Epoch 15/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1259 - accuracy: 0.9642 - val_loss: 0.0134 - val_accuracy: 0.9975\n",
            "Epoch 16/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1281 - accuracy: 0.9638 - val_loss: 0.0165 - val_accuracy: 0.9959\n",
            "Epoch 17/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1490 - accuracy: 0.9593 - val_loss: 0.0140 - val_accuracy: 0.9969\n",
            "Epoch 18/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1253 - accuracy: 0.9666 - val_loss: 0.0089 - val_accuracy: 0.9981\n",
            "Epoch 19/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1284 - accuracy: 0.9675 - val_loss: 0.0184 - val_accuracy: 0.9944\n",
            "Epoch 20/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1412 - accuracy: 0.9640 - val_loss: 0.0127 - val_accuracy: 0.9976\n",
            "Epoch 21/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1274 - accuracy: 0.9666 - val_loss: 0.0102 - val_accuracy: 0.9970\n",
            "Epoch 22/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1156 - accuracy: 0.9698 - val_loss: 0.0197 - val_accuracy: 0.9955\n",
            "Epoch 23/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1124 - accuracy: 0.9724 - val_loss: 0.0074 - val_accuracy: 0.9983\n",
            "Epoch 24/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1045 - accuracy: 0.9738 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
            "Epoch 25/25\n",
            "272/272 [==============================] - 2s 9ms/step - loss: 0.1087 - accuracy: 0.9726 - val_loss: 0.0069 - val_accuracy: 0.9986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9433106575963719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUc0PickWTty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c926495e-00cb-470b-986b-664bfd84d879"
      },
      "source": [
        "def get_cnn_v4(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.3),   \n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    model.summary()\n",
        "    return model\n",
        "train_predict(get_cnn_v4(input_shape, num_classes))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1024)              1639424   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 1,749,067\n",
            "Trainable params: 1,749,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 1.5811 - accuracy: 0.6479 - val_loss: 0.2116 - val_accuracy: 0.9556\n",
            "Epoch 2/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.3324 - accuracy: 0.9045 - val_loss: 0.0590 - val_accuracy: 0.9854\n",
            "Epoch 3/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.1933 - accuracy: 0.9436 - val_loss: 0.0379 - val_accuracy: 0.9904\n",
            "Epoch 4/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.1362 - accuracy: 0.9589 - val_loss: 0.0262 - val_accuracy: 0.9928\n",
            "Epoch 5/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.1069 - accuracy: 0.9673 - val_loss: 0.0153 - val_accuracy: 0.9955\n",
            "Epoch 6/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0914 - accuracy: 0.9726 - val_loss: 0.0108 - val_accuracy: 0.9976\n",
            "Epoch 7/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0908 - accuracy: 0.9737 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
            "Epoch 8/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0688 - accuracy: 0.9803 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
            "Epoch 9/25\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.0607 - accuracy: 0.9824 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
            "Epoch 10/25\n",
            "272/272 [==============================] - 3s 12ms/step - loss: 0.0755 - accuracy: 0.9789 - val_loss: 0.0123 - val_accuracy: 0.9967\n",
            "Epoch 11/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
            "Epoch 12/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0559 - accuracy: 0.9836 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 13/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0492 - accuracy: 0.9857 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
            "Epoch 14/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.0018 - val_accuracy: 0.9995\n",
            "Epoch 15/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0448 - accuracy: 0.9876 - val_loss: 0.0055 - val_accuracy: 0.9986\n",
            "Epoch 16/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0495 - accuracy: 0.9861 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
            "Epoch 17/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0520 - accuracy: 0.9855 - val_loss: 0.0069 - val_accuracy: 0.9985\n",
            "Epoch 18/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0530 - accuracy: 0.9861 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 19/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0392 - accuracy: 0.9884 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 20/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0530 - accuracy: 0.9868 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 21/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0421 - accuracy: 0.9891 - val_loss: 0.0036 - val_accuracy: 0.9989\n",
            "Epoch 22/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0476 - accuracy: 0.9874 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
            "Epoch 23/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
            "Epoch 24/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0503 - accuracy: 0.9879 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
            "Epoch 25/25\n",
            "272/272 [==============================] - 3s 11ms/step - loss: 0.0432 - accuracy: 0.9899 - val_loss: 0.0109 - val_accuracy: 0.9972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9748299319727891"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fWXKu46Xnq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1e44318-fc99-4b98-c0d7-07cfc3217a30"
      },
      "source": [
        "def get_cnn_v5(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.3),   \n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    model.summary()\n",
        "    return model\n",
        "train_predict(get_cnn_v5(input_shape, num_classes))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              263168    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 446,667\n",
            "Trainable params: 446,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 2.6748 - accuracy: 0.2700 - val_loss: 1.3885 - val_accuracy: 0.5918\n",
            "Epoch 2/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 1.0808 - accuracy: 0.6545 - val_loss: 0.3187 - val_accuracy: 0.8992\n",
            "Epoch 3/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.4570 - accuracy: 0.8565 - val_loss: 0.0996 - val_accuracy: 0.9748\n",
            "Epoch 4/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.2679 - accuracy: 0.9191 - val_loss: 0.0508 - val_accuracy: 0.9867\n",
            "Epoch 5/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.1913 - accuracy: 0.9418 - val_loss: 0.0469 - val_accuracy: 0.9866\n",
            "Epoch 6/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.1616 - accuracy: 0.9518 - val_loss: 0.0286 - val_accuracy: 0.9917\n",
            "Epoch 7/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.1272 - accuracy: 0.9633 - val_loss: 0.0172 - val_accuracy: 0.9947\n",
            "Epoch 8/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.1133 - accuracy: 0.9674 - val_loss: 0.0125 - val_accuracy: 0.9972\n",
            "Epoch 9/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.1039 - accuracy: 0.9695 - val_loss: 0.0118 - val_accuracy: 0.9967\n",
            "Epoch 10/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0857 - accuracy: 0.9752 - val_loss: 0.0102 - val_accuracy: 0.9974\n",
            "Epoch 11/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0957 - accuracy: 0.9726 - val_loss: 0.0137 - val_accuracy: 0.9960\n",
            "Epoch 12/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0866 - accuracy: 0.9760 - val_loss: 0.0134 - val_accuracy: 0.9967\n",
            "Epoch 13/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0798 - accuracy: 0.9787 - val_loss: 0.0115 - val_accuracy: 0.9969\n",
            "Epoch 14/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0760 - accuracy: 0.9787 - val_loss: 0.0094 - val_accuracy: 0.9974\n",
            "Epoch 15/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0858 - accuracy: 0.9766 - val_loss: 0.0064 - val_accuracy: 0.9983\n",
            "Epoch 16/25\n",
            "272/272 [==============================] - 3s 13ms/step - loss: 0.0758 - accuracy: 0.9795 - val_loss: 0.0056 - val_accuracy: 0.9986\n",
            "Epoch 17/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0755 - accuracy: 0.9794 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
            "Epoch 18/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0733 - accuracy: 0.9798 - val_loss: 0.0104 - val_accuracy: 0.9967\n",
            "Epoch 19/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0694 - accuracy: 0.9815 - val_loss: 0.0098 - val_accuracy: 0.9972\n",
            "Epoch 20/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0621 - accuracy: 0.9839 - val_loss: 0.0045 - val_accuracy: 0.9989\n",
            "Epoch 21/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0796 - accuracy: 0.9791 - val_loss: 0.0146 - val_accuracy: 0.9967\n",
            "Epoch 22/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0604 - accuracy: 0.9835 - val_loss: 0.0061 - val_accuracy: 0.9986\n",
            "Epoch 23/25\n",
            "272/272 [==============================] - 3s 13ms/step - loss: 0.0617 - accuracy: 0.9850 - val_loss: 0.0037 - val_accuracy: 0.9991\n",
            "Epoch 24/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0513 - accuracy: 0.9861 - val_loss: 0.0069 - val_accuracy: 0.9978\n",
            "Epoch 25/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0632 - accuracy: 0.9838 - val_loss: 0.0072 - val_accuracy: 0.9982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VXma8ypZSE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0789d5d-9dbf-453f-adcb-b8900ade7a84"
      },
      "source": [
        "def get_cnn_v6(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape),\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPool2D(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Flatten(),\n",
        "\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(num_classes, activation='softmax'),\n",
        "    ])\n",
        "    model.summary()\n",
        "    return model\n",
        "train_predict(get_cnn_v6(input_shape, num_classes))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              263168    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 1,496,267\n",
            "Trainable params: 1,496,267\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "272/272 [==============================] - 4s 15ms/step - loss: 2.8569 - accuracy: 0.2190 - val_loss: 1.4632 - val_accuracy: 0.5233\n",
            "Epoch 2/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 1.2315 - accuracy: 0.5946 - val_loss: 0.3769 - val_accuracy: 0.8810\n",
            "Epoch 3/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.5906 - accuracy: 0.8126 - val_loss: 0.1494 - val_accuracy: 0.9591\n",
            "Epoch 4/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.3582 - accuracy: 0.8878 - val_loss: 0.0740 - val_accuracy: 0.9770\n",
            "Epoch 5/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.2729 - accuracy: 0.9175 - val_loss: 0.0581 - val_accuracy: 0.9826\n",
            "Epoch 6/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.2241 - accuracy: 0.9314 - val_loss: 0.0391 - val_accuracy: 0.9883\n",
            "Epoch 7/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1884 - accuracy: 0.9424 - val_loss: 0.0328 - val_accuracy: 0.9905\n",
            "Epoch 8/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1617 - accuracy: 0.9529 - val_loss: 0.0284 - val_accuracy: 0.9922\n",
            "Epoch 9/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1451 - accuracy: 0.9568 - val_loss: 0.0316 - val_accuracy: 0.9914\n",
            "Epoch 10/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1431 - accuracy: 0.9584 - val_loss: 0.0199 - val_accuracy: 0.9941\n",
            "Epoch 11/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1290 - accuracy: 0.9637 - val_loss: 0.0188 - val_accuracy: 0.9941\n",
            "Epoch 12/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1240 - accuracy: 0.9641 - val_loss: 0.0145 - val_accuracy: 0.9961\n",
            "Epoch 13/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1287 - accuracy: 0.9643 - val_loss: 0.0150 - val_accuracy: 0.9958\n",
            "Epoch 14/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1246 - accuracy: 0.9652 - val_loss: 0.0261 - val_accuracy: 0.9924\n",
            "Epoch 15/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1115 - accuracy: 0.9700 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
            "Epoch 16/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1042 - accuracy: 0.9696 - val_loss: 0.0176 - val_accuracy: 0.9952\n",
            "Epoch 17/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1070 - accuracy: 0.9701 - val_loss: 0.0204 - val_accuracy: 0.9938\n",
            "Epoch 18/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0889 - accuracy: 0.9759 - val_loss: 0.0148 - val_accuracy: 0.9956\n",
            "Epoch 19/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1059 - accuracy: 0.9722 - val_loss: 0.0142 - val_accuracy: 0.9961\n",
            "Epoch 20/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1013 - accuracy: 0.9725 - val_loss: 0.0148 - val_accuracy: 0.9959\n",
            "Epoch 21/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0932 - accuracy: 0.9743 - val_loss: 0.0097 - val_accuracy: 0.9972\n",
            "Epoch 22/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1002 - accuracy: 0.9735 - val_loss: 0.0167 - val_accuracy: 0.9950\n",
            "Epoch 23/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1121 - accuracy: 0.9710 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
            "Epoch 24/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0949 - accuracy: 0.9761 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
            "Epoch 25/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0959 - accuracy: 0.9737 - val_loss: 0.0080 - val_accuracy: 0.9977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9682539682539683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F1PlRCdaPaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0286de13-b343-4bea-ca42-9bbc4b8f3804"
      },
      "source": [
        "color.rgb2gray(X_train[0]).shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zab-Ollf5sX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "87a8dacd-a87e-4320-e4b8-2e032daa8367"
      },
      "source": [
        "plt.imshow(color.rgb2gray(X_train[0]), cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5ec08784a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkNiFqASJXYhK+H+i2j8pkc2FpwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMF6EfuugWpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_gray = color.rgb2gray(X_train).reshape(-1, 32, 32, 1)\n",
        "X_test_gray = color.rgb2gray(X_test).reshape(-1, 32, 32, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhTMrDr6hFv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28d8847e-2c1f-439a-aa77-ebc698b15bbd"
      },
      "source": [
        "model = get_cnn_v5((32, 32, 1), num_classes)\n",
        "model_trained = train_model(model, X_train_gray, y_train, params_fit)\n",
        "predict(model_trained, X_test_gray, y_test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_37 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1024)              263168    \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 446,091\n",
            "Trainable params: 446,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 2.1026 - accuracy: 0.4096 - val_loss: 0.4477 - val_accuracy: 0.8742\n",
            "Epoch 2/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.4202 - accuracy: 0.8645 - val_loss: 0.1019 - val_accuracy: 0.9690\n",
            "Epoch 3/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.2095 - accuracy: 0.9341 - val_loss: 0.0579 - val_accuracy: 0.9826\n",
            "Epoch 4/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.1424 - accuracy: 0.9543 - val_loss: 0.0364 - val_accuracy: 0.9905\n",
            "Epoch 5/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.1087 - accuracy: 0.9660 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
            "Epoch 6/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0880 - accuracy: 0.9723 - val_loss: 0.0143 - val_accuracy: 0.9957\n",
            "Epoch 7/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0790 - accuracy: 0.9751 - val_loss: 0.0182 - val_accuracy: 0.9945\n",
            "Epoch 8/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0618 - accuracy: 0.9802 - val_loss: 0.0100 - val_accuracy: 0.9972\n",
            "Epoch 9/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
            "Epoch 10/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0508 - accuracy: 0.9835 - val_loss: 0.0061 - val_accuracy: 0.9981\n",
            "Epoch 11/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0520 - accuracy: 0.9831 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 12/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0493 - accuracy: 0.9841 - val_loss: 0.0073 - val_accuracy: 0.9975\n",
            "Epoch 13/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0458 - accuracy: 0.9853 - val_loss: 0.0049 - val_accuracy: 0.9983\n",
            "Epoch 14/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0390 - accuracy: 0.9886 - val_loss: 0.0057 - val_accuracy: 0.9985\n",
            "Epoch 15/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
            "Epoch 16/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
            "Epoch 17/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
            "Epoch 18/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.0050 - val_accuracy: 0.9986\n",
            "Epoch 19/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.0025 - val_accuracy: 0.9994\n",
            "Epoch 20/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 21/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0334 - accuracy: 0.9896 - val_loss: 0.0026 - val_accuracy: 0.9992\n",
            "Epoch 22/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
            "Epoch 23/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0010 - val_accuracy: 0.9998\n",
            "Epoch 24/25\n",
            "272/272 [==============================] - 4s 13ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
            "Epoch 25/25\n",
            "272/272 [==============================] - 3s 13ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0017 - val_accuracy: 0.9997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9879818594104308"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvlcGWn6jDCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preproc_img(img):\n",
        "    hsv = color.rgb2hsv(img)\n",
        "    hsv[:, :, 2] = exposure.equalize_adapthist(hsv[:, :, 2])\n",
        "    img = color.hsv2rgb(hsv)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOVNtq_5mHW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ec422132-776c-4761-f72e-889bf1597636"
      },
      "source": [
        "plt.imshow(preproc_img(X_train[400]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5f100e14e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDDOTw9qtH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad2ec70b-2e03-4ead-e0b4-bd949d77eae0"
      },
      "source": [
        "preproc_img(X_train[400]).shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UHa2zbRmPhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b973c05d-608a-4e61-a2d8-5d509a817305"
      },
      "source": [
        "X_train_prep = X_train.copy().astype(np.float32)\n",
        "X_test_prep = X_test.copy().astype(np.float32)\n",
        "\n",
        "for i in tqdm(range(X_train.shape[0])):\n",
        "    X_train_prep[i] = preproc_img(X_train[i])\n",
        "\n",
        "for i in tqdm(range(X_test.shape[0])):\n",
        "    X_test_prep[i] = preproc_img(X_test[i])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 34799/34799 [05:59<00:00, 96.89it/s] \n",
            "100%|| 4410/4410 [00:43<00:00, 100.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Je1rnmo5fn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22e1e471-8012-4b92-df6f-3df3563206e2"
      },
      "source": [
        "model = get_cnn_v6(input_shape, num_classes)\n",
        "model_trained = train_model(model, X_train_prep, y_train, params_fit)\n",
        "predict(model_trained, X_test_prep, y_test)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_49 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 1024)              263168    \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 43)                44075     \n",
            "=================================================================\n",
            "Total params: 1,496,267\n",
            "Trainable params: 1,496,267\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "272/272 [==============================] - 4s 15ms/step - loss: 1.7723 - accuracy: 0.4884 - val_loss: 0.3287 - val_accuracy: 0.8929\n",
            "Epoch 2/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.3703 - accuracy: 0.8805 - val_loss: 0.1126 - val_accuracy: 0.9645\n",
            "Epoch 3/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.2097 - accuracy: 0.9328 - val_loss: 0.0663 - val_accuracy: 0.9808\n",
            "Epoch 4/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1477 - accuracy: 0.9538 - val_loss: 0.0301 - val_accuracy: 0.9910\n",
            "Epoch 5/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.1155 - accuracy: 0.9641 - val_loss: 0.0240 - val_accuracy: 0.9924\n",
            "Epoch 6/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0946 - accuracy: 0.9715 - val_loss: 0.0192 - val_accuracy: 0.9950\n",
            "Epoch 7/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0862 - accuracy: 0.9738 - val_loss: 0.0142 - val_accuracy: 0.9958\n",
            "Epoch 8/25\n",
            "272/272 [==============================] - 4s 15ms/step - loss: 0.0706 - accuracy: 0.9778 - val_loss: 0.0178 - val_accuracy: 0.9946\n",
            "Epoch 9/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0737 - accuracy: 0.9779 - val_loss: 0.0096 - val_accuracy: 0.9973\n",
            "Epoch 10/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0625 - accuracy: 0.9803 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
            "Epoch 11/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.0099 - val_accuracy: 0.9972\n",
            "Epoch 12/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0584 - accuracy: 0.9826 - val_loss: 0.0116 - val_accuracy: 0.9966\n",
            "Epoch 13/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0546 - accuracy: 0.9835 - val_loss: 0.0060 - val_accuracy: 0.9985\n",
            "Epoch 14/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0530 - accuracy: 0.9845 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
            "Epoch 15/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0530 - accuracy: 0.9844 - val_loss: 0.0060 - val_accuracy: 0.9981\n",
            "Epoch 16/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
            "Epoch 17/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0521 - accuracy: 0.9854 - val_loss: 0.0048 - val_accuracy: 0.9987\n",
            "Epoch 18/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0400 - accuracy: 0.9889 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
            "Epoch 19/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 0.0079 - val_accuracy: 0.9978\n",
            "Epoch 20/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0461 - accuracy: 0.9867 - val_loss: 0.0060 - val_accuracy: 0.9983\n",
            "Epoch 21/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
            "Epoch 22/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0428 - accuracy: 0.9879 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
            "Epoch 23/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
            "Epoch 24/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0421 - accuracy: 0.9881 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
            "Epoch 25/25\n",
            "272/272 [==============================] - 4s 14ms/step - loss: 0.0410 - accuracy: 0.9888 - val_loss: 0.0022 - val_accuracy: 0.9993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9789115646258504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KnQDPr8q34A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}